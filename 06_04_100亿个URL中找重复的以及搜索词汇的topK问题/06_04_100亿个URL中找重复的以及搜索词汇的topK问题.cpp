/*

100亿URL找重复:

还是就是进行分流，因为相同URL一定会分配到同一台子机器上，因此对每一台子机器(可以再分流也行)进行哈希表遍历统计重复即可。

TopK问题:
分流后，对于每一个子机器，哈希词频统计后，都建立一个TOP K的小根堆，然后不同机器分别进行外部排序合并即可。

注意是小根堆:
每次来数了，如果堆还没满，就push即可
如果堆已经满了，那么堆顶是K个最大的里面的最小，因此和堆顶进行比较即可，若大于堆顶就push，小于堆顶就continue
*/